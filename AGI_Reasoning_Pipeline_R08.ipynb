{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alrahimi/AGI/blob/main/AGI_Reasoning_Pipeline_R08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf31f13c",
      "metadata": {
        "id": "bf31f13c"
      },
      "source": [
        "# AGI Reasoning Pipeline — R08\n",
        "**Focus:** Proof tracing + narrative explanation  \n",
        "**Date:** 2025-10-30  \n",
        "**Lineage:** R01→R02→R03→R04→R07→**R08**  \n",
        "\n",
        "This version adds a *human-facing* proof layer on top of the stable R07 logic pipeline:\n",
        "\n",
        "- keep: Premises vs Goals discipline  \n",
        "- keep: NL → Logic → Z3  \n",
        "- keep: “No X are Y”, “Some X are Y”, plural→singular  \n",
        "- **add:** step-by-step *reasoning narrative*  \n",
        "- **add:** “why not entailed” phrasing that sounds like an agent explaining itself\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78c3aa4f",
      "metadata": {
        "id": "78c3aa4f"
      },
      "source": [
        "## 1. Overview\n",
        "\n",
        "R08 is a *presentation* upgrade: we already know how to check entailment, but we want to **show the proof**.\n",
        "\n",
        "We do this by:\n",
        "1. Capturing all translated premises.\n",
        "2. Capturing each goal in logic form.\n",
        "3. Emitting a “pseudo-proof” script that shows how Z3 *could* have concluded the goal (for simple cases).\n",
        "4. Falling back to the R07 diagnostics when the goal is **not** entailed.\n",
        "\n",
        "This is intentionally simple and transparent so it can be embedded in an agent later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fdf73ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fdf73ed",
        "outputId": "da3a4fe8-9111-4b10-c161-10eec22675e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.3/29.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# 2. Setup\n",
        "!pip -q install z3-solver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25d25296",
      "metadata": {
        "id": "25d25296"
      },
      "outputs": [],
      "source": [
        "# 3. Imports & globals\n",
        "import re\n",
        "from z3 import *\n",
        "\n",
        "U = DeclareSort('U')\n",
        "PRED_CACHE = {}\n",
        "\n",
        "def get_pred(name, arity=1):\n",
        "    key = (name, arity)\n",
        "    if key not in PRED_CACHE:\n",
        "        dom = [U] * arity\n",
        "        PRED_CACHE[key] = Function(name, *(dom + [BoolSort()]))\n",
        "    return PRED_CACHE[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba81a579",
      "metadata": {
        "id": "ba81a579"
      },
      "outputs": [],
      "source": [
        "# 4. Canonicalization\n",
        "\n",
        "CANONICAL_NOUNS = {\n",
        "    \"men\": \"man\",\n",
        "    \"people\": \"person\",\n",
        "    \"doctors\": \"doctor\",\n",
        "    \"surgeons\": \"surgeon\",\n",
        "    \"students\": \"student\",\n",
        "    \"cats\": \"cat\",\n",
        "    \"dogs\": \"dog\",\n",
        "}\n",
        "\n",
        "def normalize_const(name: str) -> str:\n",
        "    return re.sub(r'[^a-z0-9_]', '', name.strip().lower())\n",
        "\n",
        "def noun_to_pred(n: str) -> str:\n",
        "    n = n.strip().lower()\n",
        "    if n in CANONICAL_NOUNS:\n",
        "        return CANONICAL_NOUNS[n]\n",
        "    if n.endswith(\"ies\") and len(n) > 3:\n",
        "        n = n[:-3] + \"y\"\n",
        "    elif n.endswith(\"s\") and len(n) > 3:\n",
        "        n = n[:-1]\n",
        "    return re.sub(r'[^a-z0-9_]', '_', n)\n",
        "\n",
        "def verb_phrase_to_pred(vp: str) -> str:\n",
        "    return re.sub(r'[^a-z0-9_]', '_', vp.strip().lower())\n",
        "\n",
        "def sentence_to_const(name, consts):\n",
        "    c = normalize_const(name)\n",
        "    if c not in consts:\n",
        "        consts[c] = Const(c, U)\n",
        "    return consts[c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3ab1f0c",
      "metadata": {
        "id": "f3ab1f0c"
      },
      "outputs": [],
      "source": [
        "# 5. English → Logic translator (same core as R07)\n",
        "\n",
        "ALL_X_ARE_Y    = re.compile(r'^(all|every)\\s+([a-z ]+?)\\s+are\\s+([a-z ]+)$', re.I)\n",
        "NO_X_ARE_Y     = re.compile(r'^no\\s+([a-z ]+?)\\s+are\\s+([a-z ]+)$', re.I)\n",
        "SOME_X_ARE_Y   = re.compile(r'^(some|there is a|there is an)\\s+([a-z ]+?)\\s+are?\\s+([a-z ]+)$', re.I)\n",
        "A_IS_A_X       = re.compile(r'^([A-Z][a-z0-9_]*)\\s+is\\s+(?:an?\\s+)?([a-z ]+)$')\n",
        "A_IS_NOT_X     = re.compile(r'^([A-Z][a-z0-9_]*)\\s+is\\s+not\\s+([a-z ]+)$', re.I)\n",
        "ANY_X_CAN_Y    = re.compile(r'^(any(one)?|whoever|who)\\s+(.+?)\\s+can\\s+(.+)$', re.I)\n",
        "\n",
        "def translate_sentence_to_z3(s: str, consts: dict):\n",
        "    s = s.strip().rstrip('.')\n",
        "\n",
        "    m = ALL_X_ARE_Y.match(s)\n",
        "    if m:\n",
        "        X = noun_to_pred(m.group(2))\n",
        "        Y = noun_to_pred(m.group(3))\n",
        "        x = Const('x', U)\n",
        "        fol = ForAll([x], Implies(get_pred(X)(x), get_pred(Y)(x)))\n",
        "        return {\"raw\": s, \"kind\": \"forall_pos\", \"fol\": fol, \"pretty\": f\"∀x: {X}(x) → {Y}(x)\", \"preds\": {X, Y}}\n",
        "\n",
        "    m = NO_X_ARE_Y.match(s)\n",
        "    if m:\n",
        "        X = noun_to_pred(m.group(1))\n",
        "        Y = noun_to_pred(m.group(2))\n",
        "        x = Const('x', U)\n",
        "        fol = ForAll([x], Implies(get_pred(X)(x), Not(get_pred(Y)(x))))\n",
        "        return {\"raw\": s, \"kind\": \"forall_neg\", \"fol\": fol, \"pretty\": f\"∀x: {X}(x) → ¬{Y}(x)\", \"preds\": {X, Y}}\n",
        "\n",
        "    m = SOME_X_ARE_Y.match(s)\n",
        "    if m:\n",
        "        X = noun_to_pred(m.group(2))\n",
        "        Y = noun_to_pred(m.group(3))\n",
        "        x = Const('x', U)\n",
        "        fol = Exists([x], And(get_pred(X)(x), get_pred(Y)(x)))\n",
        "        return {\"raw\": s, \"kind\": \"exists\", \"fol\": fol, \"pretty\": f\"∃x: {X}(x) ∧ {Y}(x)\", \"preds\": {X, Y}}\n",
        "\n",
        "    m = ANY_X_CAN_Y.match(s)\n",
        "    if m:\n",
        "        rest = m.group(3).strip()\n",
        "        if rest.startswith('is '):\n",
        "            rest = rest[3:]\n",
        "        X = noun_to_pred(rest)\n",
        "        Y = verb_phrase_to_pred(m.group(4))\n",
        "        x = Const('x', U)\n",
        "        fol = ForAll([x], Implies(get_pred(X)(x), get_pred(Y)(x)))\n",
        "        return {\"raw\": s, \"kind\": \"forall_can\", \"fol\": fol, \"pretty\": f\"∀x: {X}(x) → {Y}(x)\", \"preds\": {X, Y}}\n",
        "\n",
        "    m = A_IS_NOT_X.match(s)\n",
        "    if m:\n",
        "        a = m.group(1)\n",
        "        X = noun_to_pred(m.group(2))\n",
        "        aC = sentence_to_const(a, consts)\n",
        "        fol = Not(get_pred(X)(aC))\n",
        "        return {\"raw\": s, \"kind\": \"fact_neg\", \"fol\": fol, \"pretty\": f\"¬{X}({aC})\", \"preds\": {X}}\n",
        "\n",
        "    m = A_IS_A_X.match(s)\n",
        "    if m:\n",
        "        a = m.group(1)\n",
        "        X = noun_to_pred(m.group(2))\n",
        "        aC = sentence_to_const(a, consts)\n",
        "        fol = get_pred(X)(aC)\n",
        "        return {\"raw\": s, \"kind\": \"fact\", \"fol\": fol, \"pretty\": f\"{X}({aC})\", \"preds\": {X}}\n",
        "\n",
        "    return {\"raw\": s, \"kind\": \"unknown\", \"fol\": None, \"pretty\": f\"Unparsed: {s}\", \"preds\": set()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "446486fa",
      "metadata": {
        "id": "446486fa"
      },
      "outputs": [],
      "source": [
        "# 6. Input parser (Premises/Goals, multi-goal)\n",
        "\n",
        "def split_sentences(text: str):\n",
        "    parts = re.split(r'\\.\\s+|\\;\\s+|\\n', text)\n",
        "    return [p.strip() for p in parts if p.strip()]\n",
        "\n",
        "def parse_input_block(text: str):\n",
        "    premises, goals = [], []\n",
        "    for line in text.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        lower = line.lower()\n",
        "        if lower.startswith('premise:') or lower.startswith('premises:'):\n",
        "            rest = line.split(':', 1)[1]\n",
        "            premises.extend(split_sentences(rest))\n",
        "        elif lower.startswith('goal:') or lower.startswith('goals:'):\n",
        "            rest = line.split(':', 1)[1]\n",
        "            goals.extend(split_sentences(rest))\n",
        "        else:\n",
        "            premises.append(line)\n",
        "    return premises, goals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b674ef6",
      "metadata": {
        "id": "6b674ef6"
      },
      "outputs": [],
      "source": [
        "# 7. Goal → Z3 with metadata\n",
        "\n",
        "def goal_to_z3(s: str, consts: dict):\n",
        "    s = s.strip().rstrip('.')\n",
        "\n",
        "    m = re.match(r'^([A-Z][a-z0-9_]*)\\s+is\\s+(?:an?\\s+)?([a-z ]+)$', s)\n",
        "    if m:\n",
        "        a = m.group(1)\n",
        "        X = noun_to_pred(m.group(2))\n",
        "        aC = sentence_to_const(a, consts)\n",
        "        return get_pred(X)(aC), f\"{X}({aC})\", {X}, {aC}\n",
        "\n",
        "    m = re.match(r'^([A-Z][a-z0-9_]*)\\s+can\\s+(.+)$', s, re.I)\n",
        "    if m:\n",
        "        a = m.group(1)\n",
        "        Y = verb_phrase_to_pred(m.group(2))\n",
        "        aC = sentence_to_const(a, consts)\n",
        "        return get_pred(Y)(aC), f\"{Y}({aC})\", {Y}, {aC}\n",
        "\n",
        "    toks = s.split()\n",
        "    if len(toks) == 2 and re.match(r'^[A-Z]', toks[0]):\n",
        "        a = toks[0]\n",
        "        X = noun_to_pred(toks[1])\n",
        "        aC = sentence_to_const(a, consts)\n",
        "        return get_pred(X)(aC), f\"{X}({aC})\", {X}, {aC}\n",
        "\n",
        "    return None, f\"Unparsed goal: {s}\", set(), set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ae85471",
      "metadata": {
        "id": "5ae85471"
      },
      "outputs": [],
      "source": [
        "# 8. Entailment core\n",
        "\n",
        "def check_entailment(premises, goal):\n",
        "    s = Solver()\n",
        "    for p in premises:\n",
        "        s.add(p)\n",
        "    s.push()\n",
        "    s.add(Not(goal))\n",
        "    res = s.check()\n",
        "    if res == unsat:\n",
        "        s.pop()\n",
        "        return True, None\n",
        "    else:\n",
        "        model = s.model()\n",
        "        s.pop()\n",
        "        return False, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d07b051",
      "metadata": {
        "id": "8d07b051"
      },
      "outputs": [],
      "source": [
        "# 9. Proof narrator\n",
        "# We can't always get a full Z3 proof tree here, so we build a\n",
        "# HUMAN-FACING chain from the premises we *do* have.\n",
        "\n",
        "def build_proof_narrative(goal_pretty, premises_translated):\n",
        "    # Look for pattern: ∀x: A(x) → B(x)  AND  A(const)  ⇒  B(const)\n",
        "    # This covers the classic \"All men are mortal. Alex is a man. ⇒ Alex is mortal.\"\n",
        "    goal_pred = None\n",
        "    goal_const = None\n",
        "    m = re.match(r'^([a-z_]+)\\((.+)\\)$', goal_pretty)\n",
        "    if m:\n",
        "        goal_pred = m.group(1)\n",
        "        goal_const = m.group(2)\n",
        "\n",
        "    steps = []\n",
        "    if goal_pred is None:\n",
        "        steps.append(\"Could not parse goal structure for narrative.\")\n",
        "        return steps\n",
        "\n",
        "    # find rules that conclude goal_pred\n",
        "    rules = []\n",
        "    facts = []\n",
        "    for tr in premises_translated:\n",
        "        ptxt = tr[\"pretty\"]\n",
        "        # rule: ∀x: A(x) → B(x)\n",
        "        m2 = re.match(r'^∀x: ([a-z_]+)\\(x\\) → ([a-z_]+)\\(x\\)$', ptxt)\n",
        "        if m2:\n",
        "            src = m2.group(1)\n",
        "            tgt = m2.group(2)\n",
        "            rules.append((src, tgt, ptxt))\n",
        "        # fact: pred(const)\n",
        "        m3 = re.match(r'^([a-z_]+)\\((.+)\\)$', ptxt)\n",
        "        if m3 and not ptxt.startswith(\"∀x\"):\n",
        "            facts.append((m3.group(1), m3.group(2), ptxt))\n",
        "\n",
        "    # Now see if some rule tgt == goal_pred and we have the src on the same const\n",
        "    for (src, tgt, ptxt) in rules:\n",
        "        if tgt == goal_pred:\n",
        "            # do we have src(goal_const)?\n",
        "            for (fpred, fconst, ftxt) in facts:\n",
        "                if fpred == src and fconst == goal_const:\n",
        "                    steps.append(f\"1. From premise: `{ftxt}` we know `{src}({goal_const})`.\")\n",
        "                    steps.append(f\"2. From universal: `{ptxt}` we know that whenever `{src}(x)` holds, `{tgt}(x)` holds.\")\n",
        "                    steps.append(f\"3. By instantiating x = {goal_const}, we conclude `{tgt}({goal_const})`, i.e. **{goal_pretty}**.\")\n",
        "                    return steps\n",
        "\n",
        "    # If we reach here, we didn't find a simple 2-step chain\n",
        "    steps.append(\"No direct rule+fact chain found to derive this goal.\")\n",
        "    return steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3cc616e",
      "metadata": {
        "id": "c3cc616e"
      },
      "outputs": [],
      "source": [
        "# 10. Diagnostics for NOT ENTAILED\n",
        "\n",
        "def explain_failure(goal_str, goal_preds, goal_consts, premise_summaries):\n",
        "    reasons = []\n",
        "\n",
        "    all_prem_consts = set()\n",
        "    for ps in premise_summaries:\n",
        "        all_prem_consts |= ps.get(\"consts\", set())\n",
        "    if goal_consts and not goal_consts.issubset(all_prem_consts):\n",
        "        missing = goal_consts - all_prem_consts\n",
        "        reasons.append(f\"- Goal mentions constant(s) {', '.join(str(m) for m in missing)} but premises never introduce them.\")\n",
        "\n",
        "    all_prem_preds = set()\n",
        "    for ps in premise_summaries:\n",
        "        all_prem_preds |= ps.get(\"preds\", set())\n",
        "    if goal_preds and not goal_preds.issubset(all_prem_preds):\n",
        "        missingp = goal_preds - all_prem_preds\n",
        "        reasons.append(f\"- Goal predicate(s) {', '.join(missingp)} never appear in premises.\")\n",
        "\n",
        "    if not reasons and goal_preds:\n",
        "        reasons.append(\"- Premises do not provide a chain to derive this goal from existing facts.\")\n",
        "\n",
        "    if not reasons:\n",
        "        reasons.append(\"- Z3 found a model where the goal is false, so it is not a logical consequence of the premises.\")\n",
        "\n",
        "    return \"\\n\".join(reasons)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0a5fdb4",
      "metadata": {
        "id": "a0a5fdb4"
      },
      "outputs": [],
      "source": [
        "# 11. Orchestrator (R08) — adds narrative\n",
        "\n",
        "def run_pipeline(user_text: str):\n",
        "    consts = {}\n",
        "    prem_texts, goal_texts = parse_input_block(user_text)\n",
        "\n",
        "    translated = []\n",
        "    z3_premises = []\n",
        "    premise_summaries = []\n",
        "    notes = []\n",
        "\n",
        "    # translate premises\n",
        "    for p in prem_texts:\n",
        "        tr = translate_sentence_to_z3(p, consts)\n",
        "        translated.append(tr)\n",
        "        if tr[\"fol\"] is not None:\n",
        "            z3_premises.append(tr[\"fol\"])\n",
        "        else:\n",
        "            notes.append(tr[\"pretty\"])\n",
        "\n",
        "        p_consts = set(v for v in consts.values())\n",
        "        premise_summaries.append({\n",
        "            \"raw\": tr[\"raw\"],\n",
        "            \"preds\": tr.get(\"preds\", set()),\n",
        "            \"consts\": p_consts\n",
        "        })\n",
        "\n",
        "    # translate goals\n",
        "    goal_forms = []\n",
        "    for g in goal_texts:\n",
        "        g_z3, g_pretty, g_preds, g_consts = goal_to_z3(g, consts)\n",
        "        goal_forms.append((g, g_z3, g_pretty, g_preds, g_consts))\n",
        "\n",
        "    reasoning_results = []\n",
        "    for g_orig, g_z3, g_pretty, g_preds, g_consts in goal_forms:\n",
        "        if g_z3 is None:\n",
        "            reasoning_results.append({\n",
        "                \"goal\": g_orig,\n",
        "                \"status\": \"unparsed\",\n",
        "                \"message\": g_pretty,\n",
        "                \"narrative\": None\n",
        "            })\n",
        "            continue\n",
        "        entailed, model = check_entailment(z3_premises, g_z3)\n",
        "        if entailed:\n",
        "            narrative = build_proof_narrative(g_pretty, translated)\n",
        "            reasoning_results.append({\n",
        "                \"goal\": g_orig,\n",
        "                \"status\": \"entailed\",\n",
        "                \"explanation\": f\"{g_pretty} is entailed by refutation.\",\n",
        "                \"narrative\": narrative,\n",
        "                \"model\": None\n",
        "            })\n",
        "        else:\n",
        "            diag = explain_failure(g_pretty, g_preds, g_consts, premise_summaries)\n",
        "            reasoning_results.append({\n",
        "                \"goal\": g_orig,\n",
        "                \"status\": \"not_entailed\",\n",
        "                \"explanation\": f\"{g_pretty} is not implied; premises ∧ ¬goal is SAT.\",\n",
        "                \"diagnostic\": diag,\n",
        "                \"narrative\": None,\n",
        "                \"model\": str(model)\n",
        "            })\n",
        "\n",
        "    # pretty print\n",
        "    print(\"=== INPUT ===\")\n",
        "    print(\"Premises:\", \" | \".join(prem_texts) if prem_texts else \"(none)\")\n",
        "    print(\"Goals:\", \" | \".join(goal_texts) if goal_texts else \"(none)\")\n",
        "\n",
        "    print(\"\\n=== TRANSLATIONS ===\")\n",
        "    for tr in translated:\n",
        "        print(f\"{tr['raw']}  -->  {tr['pretty']}\")\n",
        "    for n in notes:\n",
        "        print(n)\n",
        "\n",
        "    print(\"\\n=== RESULTS ===\")\n",
        "    for rr in reasoning_results:\n",
        "        if rr[\"status\"] == \"entailed\":\n",
        "            print(f\"[OK] {rr['goal']} --> ENTAILED.\")\n",
        "            if rr[\"narrative\"]:\n",
        "                print(\"  Narrative:\")\n",
        "                for line in rr[\"narrative\"]:\n",
        "                    print(\"   \", line)\n",
        "        else:\n",
        "            print(f\"[NO] {rr['goal']} --> NOT ENTAILED.\")\n",
        "            print(\"  Reason:\", rr[\"explanation\"])\n",
        "            if rr.get(\"diagnostic\"):\n",
        "                print(\"  Diagnostics:\")\n",
        "                for line in rr[\"diagnostic\"].split(\"\\n\"):\n",
        "                    print(\"   \", line)\n",
        "            print(\"  Countermodel:\", rr[\"model\"])\n",
        "\n",
        "    print(\"\\n=== PREDICATES (debug) ===\")\n",
        "    for (pname, ar), fn in PRED_CACHE.items():\n",
        "        print(f\"{pname}/{ar}\")\n",
        "\n",
        "    return {\n",
        "        \"premises\": prem_texts,\n",
        "        \"goals\": goal_texts,\n",
        "        \"translations\": translated,\n",
        "        \"results\": reasoning_results,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1b45613",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1b45613",
        "outputId": "7412896b-6314-4faf-b66b-dd77131bf6e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== INPUT ===\n",
            "Premises: All men are mortal | Alex is a man.\n",
            "Goals: Alex is mortal.\n",
            "\n",
            "=== TRANSLATIONS ===\n",
            "All men are mortal  -->  ∀x: man(x) → mortal(x)\n",
            "Alex is a man  -->  man(alex)\n",
            "\n",
            "=== RESULTS ===\n",
            "[OK] Alex is mortal. --> ENTAILED.\n",
            "  Narrative:\n",
            "    1. From premise: `man(alex)` we know `man(alex)`.\n",
            "    2. From universal: `∀x: man(x) → mortal(x)` we know that whenever `man(x)` holds, `mortal(x)` holds.\n",
            "    3. By instantiating x = alex, we conclude `mortal(alex)`, i.e. **mortal(alex)**.\n",
            "\n",
            "=== PREDICATES (debug) ===\n",
            "man/1\n",
            "mortal/1\n"
          ]
        }
      ],
      "source": [
        "# 12. Demo — classic syllogism (should produce a 3-step narrative)\n",
        "demo = \"\"\"\n",
        "Premises: All men are mortal. Alex is a man.\n",
        "Goals: Alex is mortal.\n",
        "\"\"\"\n",
        "summary = run_pipeline(demo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "754c6b2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "754c6b2f",
        "outputId": "dcb1e2cb-bbe2-4746-85ae-c635431f3832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported to AGI_Reasoning_Pipeline_R08.md\n"
          ]
        }
      ],
      "source": [
        "# 13. Export MD (optional)\n",
        "def build_md(summary):\n",
        "    lines = []\n",
        "    lines.append(\"# AGI Reasoning Pipeline — R08 (Proof Narrative)\")\n",
        "    lines.append(\"## Premises\")\n",
        "    for p in summary[\"premises\"]:\n",
        "        lines.append(f\"- {p}\")\n",
        "    lines.append(\"## Goals\")\n",
        "    for g in summary[\"goals\"]:\n",
        "        lines.append(f\"- {g}\")\n",
        "    lines.append(\"## Results\")\n",
        "    for r in summary[\"results\"]:\n",
        "        if r[\"status\"] == \"entailed\":\n",
        "            lines.append(f\"- ✅ {r['goal']}\")\n",
        "            if r[\"narrative\"]:\n",
        "                lines.append(\"  - Narrative:\")\n",
        "                for line in r[\"narrative\"]:\n",
        "                    lines.append(f\"    - {line}\")\n",
        "        else:\n",
        "            lines.append(f\"- ❌ {r['goal']}\")\n",
        "            lines.append(f\"  - {r.get('diagnostic','')}\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "md_text = build_md(summary)\n",
        "with open(\"AGI_Reasoning_Pipeline_R08.md\", \"w\") as f:\n",
        "    f.write(md_text)\n",
        "print(\"Exported to AGI_Reasoning_Pipeline_R08.md\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}